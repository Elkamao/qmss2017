{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Authentification: OAuth1 vs. OAuth2\n",
    "For most APIs, it is important to note the distinction between **authentification types.** There are two types of [authentification calls](https://twython.readthedocs.io/en/latest/usage/starting_out.html) that can be made and they influence the downstream functionality of the module. They are:\n",
    "* **OAuth 1 (User Authentication):** user authenticated calls for direct interactions with users (e.g. tweeting, following people, sending DMs, etc.)\n",
    "* **OAuth 2 (Application Authentication):** application authenticated calls for making read-only calls to Twitter (e.g. searching, reading a public users timeline)\n",
    "\n",
    "Below we will only be handling **OAuth 2** authentification and subsequent calls, as this is likely the use case for data analysis (e.g. gather data, store offline, analyze offline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook APIs\n",
    "To use Facebook's API, you will first need to [register](https://developers.facebook.com/) for an application with Facebook. Once there, create and new app and fill out the requisite details (e.g. name, description, website, etc.). \n",
    "\n",
    "After registering, you will need your **App ID** and **App Secret**, which will be used to authorize your API calls. Be sure to save in a protected manner. \n",
    "\n",
    "## Searching Facebook\n",
    "The primary function with an OAuth2-authenticated Twitter instance is the search function, which returns data related to the search from the Facebook graph structure. Before detailing the search function, it's worth first going over the Facebook graph API structure.\n",
    "\n",
    "### Graph API\n",
    "From the Facebook devs, \"the Graph API is the primary way to get data out of, and put data into, Facebook's platform.\" Though the graph structure has been thoroughly described [elsewhere](https://developers.facebook.com/docs/graph-api/overview), the concise explanation is that the Graph API is structured akin to a social network in that it is comprised of the following:\n",
    "* **Nodes:** top-level classes, such as Users, Photos, Pages, and Comments\n",
    "* **Edges:** relationships between those classes, such as a Page's Photos, or a Photo's Comments\n",
    "* **Fields:** information about individual instances of those classes, such as a User's birthday, or a Page's title\n",
    "\n",
    "When searching the Facebook graph API, we identify search-relevant nodes and in turn store its associated data (fields) and identify related content via its connections (edges).\n",
    "\n",
    "### Search Types\n",
    "Facebook has [documented](https://developers.facebook.com/docs/graph-api/using-graph-api#search) the list of searchable node types and this list is recreated below:\n",
    "\n",
    "|Type|Description|q value|\n",
    "|----|-----------|-------|\n",
    "|user|Search for a person (if they allow their name to be searched for).|Name|\n",
    "|page|Search for a page.|Name|\n",
    "|event|Search for an event.|Name|\n",
    "|group|Search for a group.|Name|\n",
    "|place|Search for a place. You can narrow your search to a specific location and distance by adding the center parameter (with latitude and longitude) and an optional distance parameter (in meters).|Name|\n",
    "|placetopic|Returns a list of possible place Page topics and their IDs. Use with topic_filter=all parameter to get the full list.|None|\n",
    "|ad_*|A collection of different search options that can be used to find targeting options.|See [Targeting Options](https://developers.facebook.com/docs/graph-api/reference/v2.9/targeting)|\n",
    "\n",
    "### Function Call \n",
    "The [search function](https://developers.facebook.com/docs/graph-api/using-graph-api) accepts the following parameters:\n",
    "\n",
    "|Name|Required|Description|Example|\n",
    "|----|--------|-----------|-------|\n",
    "|type|Yes|The type of Facebook class to be searched|See above|\n",
    "|q|Yes|The content of the search query| Sam, python, doggos|\n",
    "|before|No|This is the cursor that points to the start of the page of data that has been returned.|ID|\n",
    "|after|No|This is the cursor that points to the end of the page of data that has been returned.|ID|\n",
    "|limit|No|This is the maximum number of objects that may be returned. A query may return fewer than the value of limit due to filtering.|15|\n",
    "|next|No|The Graph API endpoint that will return the next page of data. If not included, this is the last page of data. Due to how pagination works with visibility and privacy, it is possible that a page may be empty but contain a 'next' paging link. Stop paging when the 'next' link no longer appears.|URL|\n",
    "|previous|No|The Graph API endpoint that will return the previous page of data. If not included, this is the first page of data.|URL|\n",
    "|fields|No|Function returns only those fields specified.|id, name, picture|\n",
    "\n",
    "\n",
    "## Facebook-SDK\n",
    "From its [documentation page](https://facebook-sdk.readthedocs.io/en/latest/index.html):\n",
    ">This client library is designed to support the Facebook Graph API and the official Facebook JavaScript SDK, which is the canonical way to implement Facebook authentication. You can read more about the Graph API by accessing its official documentation.\n",
    "\n",
    "To install the latest version of Facebook-SDK (v3.0 at the time of writing), simply open a Terminal and input: \n",
    "\n",
    "\\> pip install -e git+https://github.com/mobolic/facebook-sdk.git#egg=facebook-sdk\n",
    "\n",
    "\n",
    "### Initializing Facebook Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import facebook\n",
    "import numpy as np\n",
    "\n",
    "## Load and store authentification keys.\n",
    "oath = np.load('facebook_oath.npz')\n",
    "APP_ID = oath['app_id'].astype(str).tolist()\n",
    "APP_SECRET = oath['app_secret'].astype(str).tolist()\n",
    "\n",
    "## Initialize Facebook graph object to receive ACCESS_TOKEN.\n",
    "graph = facebook.GraphAPI(version='2.7')\n",
    "\n",
    "## Store and save ACCESS_TOKEN.\n",
    "ACCESS_TOKEN = graph.get_app_access_token(APP_ID, APP_SECRET)\n",
    "\n",
    "## Re-initilize Facebook graph object with ACCESS_TOKEN to use it.\n",
    "graph = facebook.GraphAPI(access_token=ACCESS_TOKEN, version='2.9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': '547581871944926', 'name': 'Python Developers'},\n",
       "  {'id': '509724922449953', 'name': 'Python Tips'},\n",
       "  {'id': '100832693336856', 'name': 'Python'},\n",
       "  {'id': '346004702246198', 'name': 'Python'},\n",
       "  {'id': '1539401562941064', 'name': 'Django - Python'}],\n",
       " 'paging': {'cursors': {'after': 'NAZDZD', 'before': 'MAZDZD'},\n",
       "  'next': 'https://graph.facebook.com/v2.9/search?access_token=1415649088531508%7Cjq-ce7ouUFY_B2ePp6dQ9ob2_zc&q=python&type=page&limit=5&after=NAZDZD'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Search for all Facebook pages mentioning python.\n",
    "results = graph.search(type='page', q='python', limit=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query results are stored in a dictionary format. At the top level, there are two keys:\n",
    "* **data:** a list of dictionaries containg the results of the search.\n",
    "* **paging:** a dictionary containing information about the query itself, including the **after**, **before**, and **next** pieces of metadata which are necessary for iterative function calls.\n",
    "\n",
    "Once a particular node in the graph API has been identified, its ID can be used to query additional features of the node, including its metadat and connections. We will only highlight a few examples below, but there is [extensive documentation](https://developers.facebook.com/docs/graph-api/reference) of the fields and connections that can be searched for a particular node type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Name: Python Developers\n",
      "Page ID: 547581871944926\n",
      "Page Link: https://www.facebook.com/PythonDevelopers/\n",
      "Page Description: Everything about python\n",
      "\n",
      "For beginners, try this book http://greenteapress.com/thinkpython2/thinkpython2.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'created_time': '2017-04-16T04:30:09+0000',\n",
       "  'id': '547581871944926_1286904234679349',\n",
       "  'story': \"Python Developers shared Code.org's post.\"},\n",
       " {'created_time': '2017-04-05T23:21:15+0000',\n",
       "  'id': '547581871944926_1277468192289620',\n",
       "  'message': 'Cool code for running python with grub bootloader :)\\nhttps://github.com/biosbits/bits'},\n",
       " {'created_time': '2017-03-17T13:13:29+0000',\n",
       "  'id': '547581871944926_1260813420621764',\n",
       "  'message': 'Firebase + Python https://github.com/thisbejim/Pyrebase'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract first page and corresponding ID.\n",
    "page = results['data'][0]\n",
    "page_id = page['id']\n",
    "\n",
    "## Extract additional metadata from page.\n",
    "metadata = graph.get_object(page_id, fields='id,name,about,link')\n",
    "print('Page Name: %s' %metadata['name'])\n",
    "print('Page ID: %s' %metadata['id'])\n",
    "print('Page Link: %s' %metadata['link'])\n",
    "print('Page Description: %s' %metadata['about'])\n",
    "\n",
    "## Extract posts from this page.\n",
    "post_results = graph.get_connections(page_id, connection_name='posts', limit=3)\n",
    "post_results['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Search Results\n",
    "The list of dictionaries can very easily be amalgamated into a single Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-16T04:30:09+0000</td>\n",
       "      <td>547581871944926_1286904234679349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Python Developers shared Code.org's post.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-05T23:21:15+0000</td>\n",
       "      <td>547581871944926_1277468192289620</td>\n",
       "      <td>Cool code for running python with grub bootloa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-17T13:13:29+0000</td>\n",
       "      <td>547581871944926_1260813420621764</td>\n",
       "      <td>Firebase + Python https://github.com/thisbejim...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time                                id  \\\n",
       "0  2017-04-16T04:30:09+0000  547581871944926_1286904234679349   \n",
       "1  2017-04-05T23:21:15+0000  547581871944926_1277468192289620   \n",
       "2  2017-03-17T13:13:29+0000  547581871944926_1260813420621764   \n",
       "\n",
       "                                             message  \\\n",
       "0                                                NaN   \n",
       "1  Cool code for running python with grub bootloa...   \n",
       "2  Firebase + Python https://github.com/thisbejim...   \n",
       "\n",
       "                                       story  \n",
       "0  Python Developers shared Code.org's post.  \n",
       "1                                        NaN  \n",
       "2                                        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "## Convert each status dictionary into a Pandas Series.\n",
    "posts = [Series(post) for post in post_results['data']]\n",
    "\n",
    "## Merge into single DataFrame\n",
    "df = DataFrame(posts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "Due to the graph-like nature of Facebook, data organization/storage is a non-trivial design problem and shoudl reflect the ultimate analytic goals. For example, if one is interested only in text mining the comments of a Facebook page without caring about the structure of post-comment and user-comment relationships, then a flat structure may be appropriate. If more complex tree-like relations are desired, then nested data structures (e.g. nested file directories, JSON, XML, etc.) may be necesary. \n",
    "\n",
    "In any event, an example script is given below that mines comments from Barack Obama's Facebook Page. This script also obeys Facebook's [rate limit](https://developers.facebook.com/docs/graph-api/advanced/rate-limiting) of 200 requests/hr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: Barack Obama (ID = 6815841748)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_time</th>\n",
       "      <th>id</th>\n",
       "      <th>like_count</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-10T23:49:31+0000</td>\n",
       "      <td>10154508876046749_10154508879381749</td>\n",
       "      <td>13086</td>\n",
       "      <td>As a young Republican. We don't always see eye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-10T23:51:55+0000</td>\n",
       "      <td>10154508876046749_10154508884101749</td>\n",
       "      <td>5876</td>\n",
       "      <td>Even tho I dont agree with everything presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-10T23:49:24+0000</td>\n",
       "      <td>10154508876046749_10154508879121749</td>\n",
       "      <td>4648</td>\n",
       "      <td>So sad, especially considering who is replacin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-10T23:50:14+0000</td>\n",
       "      <td>10154508876046749_10154508880516749</td>\n",
       "      <td>3184</td>\n",
       "      <td>I'm gonna miss you Barack Obama I wish you cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-10T23:51:03+0000</td>\n",
       "      <td>10154508876046749_10154508882091749</td>\n",
       "      <td>3124</td>\n",
       "      <td>I am so very sorry for how Congress treated yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_time                                   id  like_count  \\\n",
       "0  2017-01-10T23:49:31+0000  10154508876046749_10154508879381749       13086   \n",
       "1  2017-01-10T23:51:55+0000  10154508876046749_10154508884101749        5876   \n",
       "2  2017-01-10T23:49:24+0000  10154508876046749_10154508879121749        4648   \n",
       "3  2017-01-10T23:50:14+0000  10154508876046749_10154508880516749        3184   \n",
       "4  2017-01-10T23:51:03+0000  10154508876046749_10154508882091749        3124   \n",
       "\n",
       "                                             message  \n",
       "0  As a young Republican. We don't always see eye...  \n",
       "1  Even tho I dont agree with everything presiden...  \n",
       "2  So sad, especially considering who is replacin...  \n",
       "3  I'm gonna miss you Barack Obama I wish you cou...  \n",
       "4  I am so very sorry for how Congress treated yo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import facebook\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Authentification.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load and store authentification keys.\n",
    "oath = np.load('facebook_oath.npz')\n",
    "APP_ID = oath['app_id'].astype(str).tolist()\n",
    "APP_SECRET = oath['app_secret'].astype(str).tolist()\n",
    "\n",
    "## Initialize Facebook graph object to receive ACCESS_TOKEN.\n",
    "graph = facebook.GraphAPI(version='2.7')\n",
    "\n",
    "## Store and save ACCESS_TOKEN.\n",
    "ACCESS_TOKEN = graph.get_app_access_token(APP_ID, APP_SECRET)\n",
    "\n",
    "## Re-initilize Facebook graph object with ACCESS_TOKEN to use it.\n",
    "graph = facebook.GraphAPI(access_token=ACCESS_TOKEN, version='2.9')\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Find top pages.\n",
    "results = graph.search(type='page', q='Barack Obama', limit=5)\n",
    "top_result = results['data'][0]\n",
    "print('Top results: %s (ID = %s)' %(top_result['name'], top_result['id']))\n",
    "\n",
    "## Request page metadata.\n",
    "metadata = graph.get_object(top_result['id'], fields='id,name,about,link')\n",
    "\n",
    "## Request five most recent posts.\n",
    "post_results = graph.get_connections(top_result['id'], connection_name='posts', limit=5)\n",
    "\n",
    "## Iteratively request and store the first \n",
    "## five comments from each post.\n",
    "df = []\n",
    "for post in post_results['data']:\n",
    "    \n",
    "    ## Request comments.\n",
    "    comment_results = graph.get_connections(post['id'], connection_name='comments', limit=5,\n",
    "                                            fields='id,created_time,message,like_count')\n",
    "    \n",
    "    ## Iteratively convert comments to Series. Store.\n",
    "    comments = [Series(comment) for comment in comment_results['data']]\n",
    "    df += comments\n",
    "    \n",
    "## Convert into DataFrame.\n",
    "df = DataFrame(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter APIs\n",
    "To use Twitter's API, you will first need to [register](https://apps.twitter.com/) for an application with Twitter. Once there, create and new app and fill out the requisite details (e.g. name, description, website, etc.). \n",
    "\n",
    "After registering, you will need your **Consumer Key** and **Consumuer Secret**, which will be used to authorize your API calls. Be sure to save in a protected manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching Twitter\n",
    "The primary function with an OAuth2-authenticated Twitter instance is the search function, which returns relevant Tweets based on a query. There is substantial documentation by Twitter on this function, including:\n",
    "* Search function [docstring](https://dev.twitter.com/rest/reference/get/search/tweets)\n",
    "* Search function [syntax](https://dev.twitter.com/rest/public/search)\n",
    "* Search function [best uses](https://dev.twitter.com/rest/public/timelines)\n",
    "* Search function [rate limits](https://dev.twitter.com/rest/public/rate-limiting)\n",
    "\n",
    "### Function Call \n",
    "The search function accepts the following parameters:\n",
    "\n",
    "|Name|Required|Description|Example|\n",
    "|----|--------|-----------|-------|\n",
    "|q|Yes|A UTF-8, URL-encoded search query of 500 characters maximum, including operators. Queries may additionally be limited by complexity.| @szorowi1, python, #qmss|\n",
    "|geocode|No|Returns tweets by users located within a given radius of the given latitude/longitude. The location is preferentially taking from the Geotagging API, but will fall back to their Twitter profile. The parameter value is specified by ” latitude,longitude,radius ”, where radius units must be specified as either ” mi ” (miles) or ” km ” (kilometers).|40.81207 -73.954377 1mi|\n",
    "|lang|No|Restricts tweets to the given language, given by an [ISO 639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) code.|eu, en|\n",
    "|result_type|No|Specifies what type of search results you would prefer to receive.|recent, popular, mixed (default)|\n",
    "|count|No|The number of tweets to return per page, up to a maximum of 100.|15 (default)\n",
    "|until|No|Returns tweets created before the given date. Date should be formatted as YYYY-MM-DD. Keep in mind that the search index has a **7-day limit**: no tweets will be found for a date older than one week.|2015-07-19|\n",
    "|since_id|No|Returns results with an ID greater than (that is, more recent than) the specified ID. There are limits to the number of Tweets which can be accessed through the API. If the limit of Tweets has occured since the since_id, the since_id will be forced to the oldest ID available.|12345|\n",
    "|max_id|No|Returns results with an ID less than (that is, older than) or equal to the specified ID.|54321|\n",
    "\n",
    "### Search Range\n",
    "The **max_id** and **since_id** flags are important due to the [dynamic nature](https://dev.twitter.com/rest/public/timelines) of Twitter posts. In other words, the problem with Twitter is that new posts are constantly being added. Without properly specifing flags demarcating the start- and stop-points for searching, the risk of storing duplicate Tweets is high. To combat this when making multiple Search queries, the **ID - 1** of the most recently stored Tweet should be passed as the max_id flag for the next query. In this way, the next batch of queried Tweets will begin where the previous batch left off. The **since_id** flag can similarly be used to only add Tweets newer than the previously newest Tweet collected. For more details (and a more complete explanation, see [here](https://dev.twitter.com/rest/public/timelines)).\n",
    "\n",
    "### Syntax\n",
    "Twitter has conveniently [documented](https://dev.twitter.com/rest/public/search) the syntax of search queries. Some examples are given below:\n",
    "\n",
    "|Operator|Finds Tweets|\n",
    "|--------|------------|\n",
    "|watching now|containing both “watching” and “now”. This is the default operator.|\n",
    "|“happy hour”|containing the exact phrase “happy hour”.|\n",
    "|love OR hate|containing either “love” or “hate” (or both).\n",
    "|beer -root|containing “beer” but not “root”.\n",
    "|#haiku|containing the hashtag “haiku”.\n",
    "|from:interior|sent from Twitter account “interior”.\n",
    "|to:NASA|a Tweet authored in reply to Twitter account “NASA”.\n",
    "|@NASA|mentioning Twitter account “NASA”.\n",
    "|puppy filter:media|containing “puppy” and an image or video.\n",
    "|puppy -filter:retweets|containing “puppy”, filtering out retweets|\n",
    "|hilarious filter:links|containing “hilarious” and linking to URL.\n",
    "|puppy url:amazon|containing “puppy” and a URL with the word “amazon” anywhere within it.\n",
    "|superhero since:2015-12-21|containing “superhero” and sent since date “2015-12-21” (year-month-day).\n",
    "|puppy until:2015-12-21|containing “puppy” and sent before the date “2015-12-21”.\n",
    "|movie -scary :)|containing “movie”, but not “scary”, and with a positive attitude.\n",
    "|flight :(|containing “flight” and with a negative attitude.\n",
    "|traffic ?|containing “traffic” and asking a question.|\n",
    "\n",
    "### URL Encoded Queries\n",
    "Twitter requests that all search queries be [URL-encoded](https://en.wikipedia.org/wiki/Percent-encoding). Fortunately, this is not difficult with the **urllib** python library.\n",
    "\n",
    "\\> import urllib <br\\>> urllib.parse.quote_plus(\"query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twython\n",
    "From its [Github](https://github.com/ryanmcgrath/twython):\n",
    ">Twython is the premier Python library providing an easy (and up-to-date) way to access Twitter data. Actively maintained and featuring support for Python 2.6+ and Python 3. It's been battle tested by companies, educational institutions and individuals alike. \n",
    "\n",
    "To install Twython, simply open a Terminal and input: \n",
    "\n",
    "\\> pip install python\n",
    "\n",
    "### Initializing Twitter Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from twython import Twython\n",
    "\n",
    "## Load and store authentification keys.\n",
    "oath = np.load('twitter_oath.npz')\n",
    "APP_KEY = oath['consumer_key']\n",
    "APP_SECRET = oath['consumer_secret']\n",
    "\n",
    "## Initialize twitter object to receive ACCESS_TOKEN.\n",
    "twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "\n",
    "## Store and save ACCESS_TOKEN.\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "\n",
    "## Re-initilize Twitter object with ACCESS_TOKEN to use it.\n",
    "twitter = Twython(APP_KEY, access_token=ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "## Search for Tweets using the hashtag python,\n",
    "## with positive connotation.\n",
    "query = '#python :)'\n",
    "\n",
    "## URL-encode query.\n",
    "query = urllib.parse.quote_plus(query)\n",
    "\n",
    "## Make function call.\n",
    "results = twitter.search(q=query, lang='en')\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query results are stored in a dictionary format. At the top level, there are two keys:\n",
    "* **statuses:** a list of dictionaries containg the results of the search.\n",
    "* **search_metadata:** a dictionary containing information about the query itself, including the max_id and since_id\n",
    "\n",
    "Each dictionary in \"statuses\" contains a large amount of information, including: \n",
    "* **Tweet ID:** id\n",
    "* **Tweet creation date:** created_at\n",
    "* **Tweet text:** text\n",
    "* **Retweet count:** retweet_count\n",
    "* **Favorite count:** favorite_count\n",
    "* **Coordinates:** coordinates (if available). \n",
    "\n",
    "\"statuses\" also contains several additional keys that store further dictionaries of information, including: \n",
    "* **User information:** user\n",
    "* **Tweet metadata:** metadata\n",
    "* **Content of retweeted status:** retweeted_status (if applicable)\n",
    "\n",
    "### Aggregating Search Results\n",
    "The list of dictionaries can very easily be amalgamated into a single Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>lang</th>\n",
       "      <th>place</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:14 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212650729205760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>philomystic foreadvertise\\n by Jared Haer\\nCar...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 75925071, 'id_str': '75925071', 'name':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:01 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212595939012608</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>How to remove a key from a python dictionary? ...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 747460774998605825, 'id_str': '74746077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:16:59 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212339935367170</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @LearningatCisco: UCS #Python SDKs - Free w...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 7322202, 'id_str': '7322202', 'name': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:16:43 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212269840171009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @pythonbot_: A Concise Introduction To Prog...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 856280704098938881, 'id_str': '85628070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:16:41 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212260587524096</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Oracle And Open Source: Includes Perl, Linux, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 726709023563747328, 'id_str': '72670902...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  favorite_count  \\\n",
       "0         None        None  Fri Jun 09 16:18:14 +0000 2017               0   \n",
       "1         None        None  Fri Jun 09 16:18:01 +0000 2017               0   \n",
       "2         None        None  Fri Jun 09 16:16:59 +0000 2017               0   \n",
       "3         None        None  Fri Jun 09 16:16:43 +0000 2017               0   \n",
       "4         None        None  Fri Jun 09 16:16:41 +0000 2017               0   \n",
       "\n",
       "   favorited   geo                  id in_reply_to_screen_name  \\\n",
       "0      False  None  873212650729205760                    None   \n",
       "1      False  None  873212595939012608                    None   \n",
       "2      False  None  873212339935367170                    None   \n",
       "3      False  None  873212269840171009                    None   \n",
       "4      False  None  873212260587524096                    None   \n",
       "\n",
       "  in_reply_to_status_id in_reply_to_status_id_str  \\\n",
       "0                  None                      None   \n",
       "1                  None                      None   \n",
       "2                  None                      None   \n",
       "3                  None                      None   \n",
       "4                  None                      None   \n",
       "\n",
       "                         ...                         in_reply_to_user_id_str  \\\n",
       "0                        ...                                            None   \n",
       "1                        ...                                            None   \n",
       "2                        ...                                            None   \n",
       "3                        ...                                            None   \n",
       "4                        ...                                            None   \n",
       "\n",
       "  is_quote_status  lang place possibly_sensitive retweet_count  retweeted  \\\n",
       "0           False    en  None              False             0      False   \n",
       "1           False    en  None              False             0      False   \n",
       "2           False    en  None              False             1      False   \n",
       "3           False    en  None              False             1      False   \n",
       "4           False    en  None              False             0      False   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  philomystic foreadvertise\\n by Jared Haer\\nCar...     False   \n",
       "1  How to remove a key from a python dictionary? ...     False   \n",
       "2  RT @LearningatCisco: UCS #Python SDKs - Free w...     False   \n",
       "3  RT @pythonbot_: A Concise Introduction To Prog...     False   \n",
       "4  Oracle And Open Source: Includes Perl, Linux, ...     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'id': 75925071, 'id_str': '75925071', 'name':...  \n",
       "1  {'id': 747460774998605825, 'id_str': '74746077...  \n",
       "2  {'id': 7322202, 'id_str': '7322202', 'name': '...  \n",
       "3  {'id': 856280704098938881, 'id_str': '85628070...  \n",
       "4  {'id': 726709023563747328, 'id_str': '72670902...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "## Convert each status dictionary into a Pandas Series.\n",
    "statuses = [Series(status) for status in results['statuses']]\n",
    "\n",
    "## Merge into single DataFrame\n",
    "df = DataFrame(statuses)\n",
    "\n",
    "## Drop unnecessary columns.\n",
    "df = df.drop(['entities', 'extended_entities', 'id_str', 'metadata', 'retweeted_status', 'source'], 1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is especially easy now to lookup and access the content of Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     philomystic foreadvertise\\n by Jared Haer\\nCar...\n",
       "1     How to remove a key from a python dictionary? ...\n",
       "2     RT @LearningatCisco: UCS #Python SDKs - Free w...\n",
       "3     RT @pythonbot_: A Concise Introduction To Prog...\n",
       "4     Oracle And Open Source: Includes Perl, Linux, ...\n",
       "5     RT @pythonbot_: Hacking: 3 Manuscripts - Bitco...\n",
       "6     The Definitive Guide To Django: Web Developmen...\n",
       "7     RT @pythonbot_: Building Restful Python Web Se...\n",
       "8     RT @pythonbot_: Learning Penetration Testing W...\n",
       "9     Latest @ActiveState blog features @ZooFood's d...\n",
       "10    RT @BigData_LDN: Which programming language sh...\n",
       "11    6/23-@Calvinhp will present his voting app cre...\n",
       "12    RT @JohnSnowLabs: Analyzing #HealthIT Provider...\n",
       "13    Something worth look at before next project. H...\n",
       "14    RT @SleekDeals: Become an #Expert in #WebDevel...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed, several of the secondary dictionaries (e.g. entities, metadata, user) are stored as such in their respective columns. These can be deleted, or new functions can be written to extract relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>lang</th>\n",
       "      <th>place</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:14 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212650729205760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>philomystic foreadvertise\\n by Jared Haer\\nCar...</td>\n",
       "      <td>False</td>\n",
       "      <td>75925071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:01 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212595939012608</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>How to remove a key from a python dictionary? ...</td>\n",
       "      <td>False</td>\n",
       "      <td>747460774998605825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:16:59 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212339935367170</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @LearningatCisco: UCS #Python SDKs - Free w...</td>\n",
       "      <td>False</td>\n",
       "      <td>7322202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:16:43 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212269840171009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @pythonbot_: A Concise Introduction To Prog...</td>\n",
       "      <td>False</td>\n",
       "      <td>856280704098938881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:16:41 +0000 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212260587524096</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Oracle And Open Source: Includes Perl, Linux, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>726709023563747328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  favorite_count  \\\n",
       "0         None        None  Fri Jun 09 16:18:14 +0000 2017               0   \n",
       "1         None        None  Fri Jun 09 16:18:01 +0000 2017               0   \n",
       "2         None        None  Fri Jun 09 16:16:59 +0000 2017               0   \n",
       "3         None        None  Fri Jun 09 16:16:43 +0000 2017               0   \n",
       "4         None        None  Fri Jun 09 16:16:41 +0000 2017               0   \n",
       "\n",
       "   favorited   geo                  id in_reply_to_screen_name  \\\n",
       "0      False  None  873212650729205760                    None   \n",
       "1      False  None  873212595939012608                    None   \n",
       "2      False  None  873212339935367170                    None   \n",
       "3      False  None  873212269840171009                    None   \n",
       "4      False  None  873212260587524096                    None   \n",
       "\n",
       "  in_reply_to_status_id in_reply_to_status_id_str         ...          \\\n",
       "0                  None                      None         ...           \n",
       "1                  None                      None         ...           \n",
       "2                  None                      None         ...           \n",
       "3                  None                      None         ...           \n",
       "4                  None                      None         ...           \n",
       "\n",
       "  in_reply_to_user_id_str is_quote_status  lang place possibly_sensitive  \\\n",
       "0                    None           False    en  None              False   \n",
       "1                    None           False    en  None              False   \n",
       "2                    None           False    en  None              False   \n",
       "3                    None           False    en  None              False   \n",
       "4                    None           False    en  None              False   \n",
       "\n",
       "  retweet_count  retweeted                                               text  \\\n",
       "0             0      False  philomystic foreadvertise\\n by Jared Haer\\nCar...   \n",
       "1             0      False  How to remove a key from a python dictionary? ...   \n",
       "2             1      False  RT @LearningatCisco: UCS #Python SDKs - Free w...   \n",
       "3             1      False  RT @pythonbot_: A Concise Introduction To Prog...   \n",
       "4             0      False  Oracle And Open Source: Includes Perl, Linux, ...   \n",
       "\n",
       "  truncated                user  \n",
       "0     False            75925071  \n",
       "1     False  747460774998605825  \n",
       "2     False             7322202  \n",
       "3     False  856280704098938881  \n",
       "4     False  726709023563747328  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define new user extract function.\n",
    "extract_user_info = np.vectorize( lambda d: d['id'] if isinstance(d,dict) else np.nan )\n",
    "\n",
    "## Apply.\n",
    "df.user = extract_user_info(df.user)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "Twitter [rate limits](https://dev.twitter.com/rest/public/rate-limiting) API queries, meaning that we need to be aware of how often we are querying. According to [this table](https://dev.twitter.com/rest/public/rate-limits), it appears the OAuth 2 search function is limited to 450 requests per 15 minute window. In other words, we are limited to one request every 2 seconds. \n",
    "\n",
    "Below, we make use of the code previously written and the time library to make 10 search queries merge and store the results while obeying the rate limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>metadata</th>\n",
       "      <th>place</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:22 +0000 2017</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 870437204333559811, 'id_str'...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212685856395265</td>\n",
       "      <td>873212685856395265</td>\n",
       "      <td>...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Fri Jun 02 00:29:37 +0000 2017...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @MadamMelanin: Kali Uchis | This singer fro...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 123438140, 'id_str': '123438140', 'name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:18 +0000 2017</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212668970250244</td>\n",
       "      <td>873212668970250244</td>\n",
       "      <td>...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6544</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Thu Jun 08 16:16:27 +0000 2017...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @AlanDersh: Senators should ask Comey the n...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 535325424, 'id_str': '535325424', 'name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jun 09 16:18:17 +0000 2017</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>873212665530691586</td>\n",
       "      <td>873212665530691586</td>\n",
       "      <td>...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6544</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Thu Jun 08 16:16:27 +0000 2017...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @AlanDersh: Senators should ask Comey the n...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 3313514424, 'id_str': '3313514424', 'na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  \\\n",
       "0         None        None  Fri Jun 09 16:18:22 +0000 2017   \n",
       "1         None        None  Fri Jun 09 16:18:18 +0000 2017   \n",
       "2         None        None  Fri Jun 09 16:18:17 +0000 2017   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'id': 870437204333559811, 'id_str'...               0   \n",
       "1                                                NaN               0   \n",
       "2                                                NaN               0   \n",
       "\n",
       "   favorited   geo                  id              id_str  \\\n",
       "0      False  None  873212685856395265  873212685856395265   \n",
       "1      False  None  873212668970250244  873212668970250244   \n",
       "2      False  None  873212665530691586  873212665530691586   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "\n",
       "                                            metadata place possibly_sensitive  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...  None              False   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...  None                NaN   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...  None                NaN   \n",
       "\n",
       "  retweet_count retweeted                                   retweeted_status  \\\n",
       "0           119     False  {'created_at': 'Fri Jun 02 00:29:37 +0000 2017...   \n",
       "1          6544     False  {'created_at': 'Thu Jun 08 16:16:27 +0000 2017...   \n",
       "2          6544     False  {'created_at': 'Thu Jun 08 16:16:27 +0000 2017...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  RT @MadamMelanin: Kali Uchis | This singer fro...     False   \n",
       "1  RT @AlanDersh: Senators should ask Comey the n...     False   \n",
       "2  RT @AlanDersh: Senators should ask Comey the n...     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'id': 123438140, 'id_str': '123438140', 'name...  \n",
       "1  {'id': 535325424, 'id_str': '535325424', 'name...  \n",
       "2  {'id': 3313514424, 'id_str': '3313514424', 'na...  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time, urllib\n",
    "import numpy as np\n",
    "from twython import Twython\n",
    "from pandas import Series, DataFrame, concat\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Authentification.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load and store authentification keys.\n",
    "oath = np.load('twitter_oath.npz')\n",
    "APP_KEY = oath['consumer_key']\n",
    "APP_SECRET = oath['consumer_secret']\n",
    "\n",
    "## Initialize twitter object to receive ACCESS_TOKEN.\n",
    "twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "\n",
    "## Store and save ACCESS_TOKEN.\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()\n",
    "\n",
    "## Re-initilize Twitter object with ACCESS_TOKEN to use it.\n",
    "twitter = Twython(APP_KEY, access_token=ACCESS_TOKEN)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Search for Tweens from Columbia University\n",
    "## filtering out any retweets.\n",
    "query = 'from:columbia -filter:retweets'\n",
    "\n",
    "## URL-encode query.\n",
    "query = urllib.parse.quote_plus(query)\n",
    "\n",
    "max_id = False\n",
    "for _ in range(10):\n",
    "    \n",
    "    ## Make function call.\n",
    "    if not max_id: results = twitter.search(q=query, lang='en')\n",
    "    else: results = twitter.search(q=query, lang='en', max_id = max_id-1)\n",
    "        \n",
    "    ## Convert each status dictionary into a Pandas Series.\n",
    "    statuses = [Series(status) for status in results['statuses']]\n",
    "    \n",
    "    ## Merge.\n",
    "    if not max_id: df = DataFrame(statuses)\n",
    "    else: df = concat([df,DataFrame(statuses)])\n",
    "        \n",
    "    ## Extract max_id\n",
    "    max_id = results['search_metadata']['max_id']\n",
    "        \n",
    "    ## Sleep timer.\n",
    "    time.sleep(2)\n",
    "\n",
    "## Display results.\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "There are a number of other python libraries capable of making Twitter queries (see [here](https://dev.twitter.com/resources/twitter-libraries) for list). Other user recommended libraries are [Python-Twitter](https://github.com/bear/python-twitter), [Tweepy](https://github.com/tweepy/tweepy), and [TwitterAPI](https://github.com/geduldig/TwitterAPI). \n",
    "\n",
    "For further reading, there are also a number of tutorials [here](http://nodotcom.org/python-twitter-tutorial.html), [here](http://socialmedia-class.org/twittertutorial.html), and [here](http://adilmoujahid.com/posts/2014/07/twitter-analytics/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit APIs\n",
    "To use Reddit's API, you will first need to [register](https://github.com/reddit/reddit/wiki/OAuth2) for an application with Twitter. Once there, create a new app and fill out the requisite details (e.g. name, description, etc.). \n",
    "\n",
    "After registering, you will need your **Client ID** and **Consumuer Secret**, which will be used to authorize your API calls. Be sure to save in a protected manner. In addition, you will need to define a **user agent** code that follows the naming conventions outlined [here](https://github.com/reddit/reddit/wiki/API#rules).\n",
    "\n",
    "The complete [Reddit API](https://www.reddit.com/dev/api/) is a helpful resource, but is predominantly full of information of OAuth 2 authentification accounts. We will largely focus on OAuth 2 operations, i.e. searching through publicly accessible Reddit content.\n",
    "\n",
    "## PRAW\n",
    "The Python Reddit API Wrapper, or [PRAW](https://github.com/praw-dev/praw), is:\n",
    ">... a python package that allows for simple access to Reddit's API. PRAW aims to be easy to use and internally follows all of Reddit's API rules. With PRAW there's no need to introduce sleep calls in your code. Give your client an appropriate user agent and you're set.\n",
    "\n",
    "To install PRAW, simply open a terminal and input:\n",
    "\n",
    "\\> pip install praw\n",
    "\n",
    "It should also be noted that PRAW handles Reddit's [rate limit](https://github.com/reddit/reddit/wiki/API#rules) of 60 requests per minute (1 request/sec; [source](https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html)).\n",
    "\n",
    "### Initializing  Reddit Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<praw.reddit.Reddit at 0x7fa684fb7518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from praw import Reddit\n",
    "\n",
    "## Load and store authentification keys.\n",
    "oath = np.load('reddit_oath.npz')\n",
    "CLIENT_ID = oath['client_id'].astype(str).tolist()\n",
    "CLIENT_SECRET = oath['client_secret'].astype(str).tolist()\n",
    "USER_AGENT = oath['user_agent'].astype(str).tolist()\n",
    "\n",
    "## Initialize Reddit object to receive ACCESS_TOKEN.\n",
    "reddit = Reddit(client_id=CLIENT_ID, client_secret=CLIENT_SECRET, user_agent=USER_AGENT)\n",
    "reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Querying \n",
    "To understand querying for Reddit, one first has to know a little about the organization of Reddit itself. For the uninitiated, Reddit is a forum website comprised of multiple specialty forums, known as **subreddits**. An individual subreddit is, in itself made up of **submissions**, or user posts to the subreddit. Submissions are made of the **body**, or content, of the post and **comments** left in response to the post. **Users** generate submissions and comments, and are also members of different subreddits.\n",
    "\n",
    "Each of these individual instances (e.g. subreddits, submissions, comments, users) are queryable. The pseudo-hierarchical structure of Reddit, however, means that querying a higher-order class will usually return lower level classes (e.g. querying a subreddit will return submissions, querying a submission will return comments). Reflecting the structure of Reddit, we will cover each type of query in a top-down fashion.\n",
    "\n",
    "### Querying Subreddits\n",
    "To search over the space of subreddits (i.e. over all forums), there are two main functions: **subreddits** and **random_subreddit**. The former provides different tools for finding subreddits, including providing a list of default and popular subreddits; the latter randomly selects and returns an instance of one subreddit. If performing search, Reddit's search syntax can be found [here](https://www.reddit.com/wiki/search). Below are examples of both function types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Subreddit(display_name='avocadosgonewild'),\n",
       " Subreddit(display_name='avocado'),\n",
       " Subreddit(display_name='avocados'),\n",
       " Subreddit(display_name='enlightenedavocadomen'),\n",
       " Subreddit(display_name='unexpectedavocado')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Search for subreddits involving avocados.\n",
    "avocado_subreddits = reddit.subreddits.search('avocado')\n",
    "avocado_subreddits = list(avocado_subreddits)\n",
    "avocado_subreddits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit(display_name='XFiles')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Return random subreddit.\n",
    "random_subreddit = reddit.random_subreddit()\n",
    "random_subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Submissions\n",
    "After identifying a subreddit of interest, submissions are queried. Submissions can be queried directly from a subreddit instance using the **subreddit.submissions** attribute.\n",
    "\n",
    "Similar to querying for subreddits, querying submissions of a subreddit will return a generator instance. This can be traversed to return submissions to that subreddit. The submissions function has three attributes:\n",
    "* **start:** A UNIX timestamp indicating the earliest creation time of submission yielded during the call.\n",
    "* **end:** A UNIX timestamp indicating the latest creation time of a submission yielded during the call\n",
    "* **extra_query:**  cloudsearch query that will be used to further filter results.\n",
    "\n",
    "We demonstrate with the r/learnpython subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Submission(id='6es1xr'),\n",
       " Submission(id='6erq6p'),\n",
       " Submission(id='6ermnb'),\n",
       " Submission(id='6er5ub'),\n",
       " Submission(id='6er3b9')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime, time\n",
    "\n",
    "## Initialize subreddit instance.\n",
    "subreddit = reddit.subreddit('learnpython')\n",
    "\n",
    "## Define start and end dates \n",
    "start = '2017-06-01'\n",
    "start = time.mktime(datetime.datetime.strptime(start, '%Y-%m-%d').timetuple()) # Convert to UNIX time.\n",
    "end = '2017-06-02'\n",
    "end = time.mktime(datetime.datetime.strptime(end, '%Y-%m-%d').timetuple()) # Convert to UNIX time.\n",
    "\n",
    "## Query submissions.\n",
    "submissions = subreddit.submissions(start=start, end=end)\n",
    "submissions = list(submissions)\n",
    "submissions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Bodies & Comments\n",
    "Once a submission has been identified, its content can be queried. Note from above that submissions are identified by their respective **IDs**. \n",
    "\n",
    "At the level of submission there are many stored pieces of data, including: author, title, subreddit, and upvotes/downvotes/score. There is also the body of the submission, stored as its **selftext**. Finally, the comments on the submission can also be investigated. These have similar attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: trexmixx\n",
      "Title: Running a python file continuously (best practice)\n",
      "Score: 46\n",
      "Body: Somewhat new to practical python.  I'm working on making a twitter bot- whats the best practice for keeping a script running continuously?  I've looked into hosting it on a free web server online and getting a raspberry pi and keeping it on - are either of these actually legitimate?  I'm out of my depth.\n"
     ]
    }
   ],
   "source": [
    "## Take first submission.\n",
    "submission = submissions[1]\n",
    "\n",
    "## Print metadata.\n",
    "print('Author: %s' %submission.author)\n",
    "print('Title: %s' %submission.title)\n",
    "print('Score: %s' %submission.score)\n",
    "print('Body: %s' %submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extract comments.\n",
    "comments = submission.comments\n",
    "comments = list(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: elbiot\n",
      "Score: 22\n",
      "Body: Either of those are fine options. Write a systemd service, since that's how continually running services are usually done on Linux (now that systemd is in almost all of the major distros).\n"
     ]
    }
   ],
   "source": [
    "## Take first comment.\n",
    "comment = comments[0]\n",
    "\n",
    "## Print metadata.\n",
    "print('Author: %s' %comment.author)\n",
    "print('Score: %s' %comment.score)\n",
    "print('Body: %s' %comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "Due to the hierarchical nature of Reddit, data organization/storage is a non-trivial design problem and shoudl reflect the ultimate analytic goals. For example, if one is interested only in text mining the submissions of subreddit without caring about the structure of submission-comment and comment-comment relationships, then a flat structure may be appropriate. If more complex tree-like relations are desired, then nested data structures (e.g. nested file directories, JSON, XML, etc.) may be necesary. \n",
    "\n",
    "In any event, an example script is given below that mines submissions & comments from r/Anxiety, as part of a larger project of predicting symptoms clusters from text. This script also obeys Reddit's OAuth 2 rate limit of 60 requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Date</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iwabo1234</td>\n",
       "      <td>1.496376e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>I'm getting my wisdom teeth removed tomorrow (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>winning34</td>\n",
       "      <td>1.496382e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>Dental anxiety is a very real thing, but thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kajjaznam1</td>\n",
       "      <td>1.496408e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>I took one out 2 days ago, it didn't hurt beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barbar21</td>\n",
       "      <td>1.496375e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>So long story short i think i have anxiety iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solidpancake</td>\n",
       "      <td>1.496383e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>Once I heard it described as that feeling you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User          Date  Score  \\\n",
       "0     iwabo1234  1.496376e+09      2   \n",
       "1     winning34  1.496382e+09      2   \n",
       "2    kajjaznam1  1.496408e+09      2   \n",
       "3      Barbar21  1.496375e+09      6   \n",
       "4  solidpancake  1.496383e+09      4   \n",
       "\n",
       "                                                Text  \n",
       "0  I'm getting my wisdom teeth removed tomorrow (...  \n",
       "1  Dental anxiety is a very real thing, but thank...  \n",
       "2  I took one out 2 days ago, it didn't hurt beca...  \n",
       "3  So long story short i think i have anxiety iss...  \n",
       "4  Once I heard it described as that feeling you ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime, time\n",
    "from praw import Reddit\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Authentification.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load and store authentification keys.\n",
    "oath = np.load('reddit_oath.npz')\n",
    "CLIENT_ID = oath['client_id'].astype(str).tolist()\n",
    "CLIENT_SECRET = oath['client_secret'].astype(str).tolist()\n",
    "USER_AGENT = oath['user_agent'].astype(str).tolist()\n",
    "\n",
    "## Initialize Reddit object to receive ACCESS_TOKEN.\n",
    "reddit = Reddit(client_id=CLIENT_ID, client_secret=CLIENT_SECRET, user_agent=USER_AGENT)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Initialize posts (bodies + comments).\n",
    "posts = []\n",
    "\n",
    "## Define start and end dates \n",
    "start = '2017-06-01'\n",
    "start = time.mktime(datetime.datetime.strptime(start, '%Y-%m-%d').timetuple()) # Convert to UNIX time.\n",
    "end = '2017-06-02'\n",
    "end = time.mktime(datetime.datetime.strptime(end, '%Y-%m-%d').timetuple()) # Convert to UNIX time.\n",
    "\n",
    "## Load subreddit.\n",
    "subreddit = reddit.subreddit('Anxiety')\n",
    "\n",
    "for submission in subreddit.submissions(start=start, end=end):\n",
    "    \n",
    "    ## Parse submission.\n",
    "    series = Series([submission.author, submission.created_utc, submission.score, submission.selftext],\n",
    "                    index=['User','Date','Score','Text'])\n",
    "    posts.append(series)\n",
    "    \n",
    "    ## Iterate over comments.\n",
    "    for comment in submission.comments:\n",
    "        \n",
    "        ## Parse submission.\n",
    "        series = Series([comment.author, comment.created_utc, comment.score, comment.body],\n",
    "                        index=['User','Date','Score','Text'])\n",
    "        posts.append(series)\n",
    "        \n",
    "\n",
    "## Merge.\n",
    "posts = DataFrame(posts)\n",
    "posts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "For further reading, there are also a number of tutorials [here](https://praw.readthedocs.io/en/latest/tutorials/comments.html), [here](http://pythonforengineers.com/build-a-reddit-bot-part-1/), and [here](http://minimaxir.com/2015/10/reddit-bigquery/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Popular APIs\n",
    "## AWS\n",
    "Unfortunately, the developer of the tutorial did not have access to any Amazon Web Service applications, so a more proper tutorial could not be written. [Boto](https://github.com/boto/boto3) is the python API for AWS, and it has many great [tutorials](https://boto3.readthedocs.io/en/latest/guide/quickstart.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "814px",
    "left": "0px",
    "right": "1057px",
    "top": "106px",
    "width": "164px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
